<!DOCTYPE HTML>


<html lang="en">
<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Shichao Wu</title>
  
  <meta name="author" content="Shichao Wu">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/robots-and-humans.png">
  
  <style>
	.largeText {
	  font-size: 36px;
	}
  </style>
  
</head> 


<body>
<table style="width:1000px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody><tr>
        <td halign="center">
            <p align="center">
                <font size="6">Selected Publications</font>
            </p>
        </td>
    </tr>
    <tr>
        <td>
		Notes: Joint first authors are indicated using #, and corresponding authors using *.	
		<ol>
			
		<!--  Publications Sorted with Date -->
		
		
		<li> DFSC-DA: Dominant Frequency Segmented Conformer with Domain Adaptation for Acoustic Footstep-based Person Identification,
		Shichao Wu*, Jinzheng Guang, Wei Wu, Gongping Chen, 
		<strong><a href="https://doi.org/10.1016/j.eswa.2025.128827"> Expert Systems With Applications </a></strong>, 294(2025): 128827. [SCI]
		</li>
		
		<br>
		<li> CRATI: Contrastive Representation-based Multimodal Sound Event Localization and Detection,
		Shichao Wu, Yongru Wang, Yushan Jiang, Qianyi Zhang, Jingtai Liu*, 
		<strong><a href="https://doi.org/10.1016/j.knosys.2024.112692"> Knowledge-Based Systems </a></strong>, 305 (2024): 112692. [SCI]
		</li>
		
		<br>
		<li> AFPILD: Acoustic Footstep Dataset Collected Using One Microphone Array and LiDAR Sensor for Person Identification and Localization,
		Shichao Wu, Shouwang Huang, Zicheng Liu, Qianyi Zhang, Jingtai Liu*, 
		<strong><a href="https://doi.org/10.1016/j.inffus.2023.102181"> Information Fusion</a></strong>, 104 (2024): 102181.
		[SCI | <a href="https://github.com/NkuSRLab/AFPILD-CRNN">dataset & code</a>]</li>
		
		<br>
		<li> Hierarchical Context-Based Emotion Recognition with Scene Graphs, 
		Shichao Wu, Lei Zhou, Zhengxi Hu and Jingtai Liu*, 
		<strong><a href="https://doi.org/10.1109/TNNLS.2022.3196831"> IEEE Transactions on Neural Networks and Learning Systems</a></strong>, 2024, 35(3): 3725-3739.
		[SCI] </li>
		
		<br>
		<li> SemanticTopoLoop: Semantic Loop Closure with 3D Topological Graph Based on Quadric-Level Object Map, 
		Zhenzhong Cao, Jingtai Liu*, Qianyi Zhang, Shichao Wu, Zhengxi Hu, Jinzheng Guang, 
		<strong><a href="https://doi.org/10.1109/LRA.2024.3374169"> IEEE Robotics and Automation Letters</a></strong>, 9(5), 4257-4264, 2024.
		[SCI] </li>
		
		<br>
		<li> RPEA: A Residual Path Network with Efficient Attention for 3D Pedestrian Detection from LiDAR Point Clouds, 
		Jinzheng Guang, Zhengxi Hu, Shichao Wu, Qianyi Zhang, Jingtai Liu*, 
		<strong><a href="https://doi.org/10.1016/j.eswa.2024.123497"> Expert Systems with Applications</a></strong>, 249 (2024): 123497.		
		[SCI] </li>		
		
		<br>
		<li> DCCLA: Dense Cross Connections with Linear Attention for LiDAR-based 3D Pedestrian Detection,
		Jinzheng Guang, Shichao Wu, Zhengxi Hu, Qianyi Zhang, Peng Wu, Jingtai Liu*, 
		<strong><a href="https://doi.org/10.1109/TCSVT.2024.3515996"> IEEE Transactions on Circuits and Systems for Video Technology </a></strong>, 2024. [SCI]
		</li>
		
		<br>
		<li> 基于3D高斯溅射的3维重建技术综述[Survey of 3D Reconstruction Techniques Based on 3D Gaussian Splatting],
		曹振中, 光金正, 张千一, 胡郑希, 吴仕超, 刘景泰*, 
		<strong><a href="https://doi.org/10.13973/j.cnki.robot.240088"> 机器人 </a></strong>, 2024. [EI]
		</li>
		
		
		<br>
		<li> Advanced Acoustic Footstep-based Person Identification Dataset and Method Using Multimodal Feature Fusion, 
		Shichao Wu, Xiaolin Zhai, Zhengxi Hu, Yue Sun, Jingtai Liu*, 
		<strong><a href="https://doi.org/10.1016/j.knosys.2023.110331"> Knowledge-Based Systems</a></strong>, 264 (2023): 110331.		
		[SCI] | <a href="https://github.com/NkuSRLab/AFPIDII-AFPINet">dataset & code</a>]</li>
		
		<br>		
		<li> HAAC: Hierarchical Audio Augmentation Chain for ACCDOA Described Sound Event Localization and Detection, 
		Shichao Wu, Yongru Wang, Zhengxi Hu, Jingtai Liu*, 
		<strong><a href="https://doi.org/10.1016/j.apacoust.2023.109541">Applied Acoustics</a></strong>, 211 (2023): 109541.
		[SCI] </li>
		
		<br>		
		<li> Improve Computing Efficiency and Motion Safety by Analyzing Environment With Graphics, 
		Qianyi Zhang, Shichao Wu, Yuhang Jia, Yuang Xu, Jingtai Liu*, 
		<strong><a href="https://doi.org/10.1016/j.apacoust.2023.109541">IEEE Transactions on Automation Science and Engineering (TASE)</a></strong>, 2023.		
		[SCI] </li>
				
		<br>
		<li> Learning Group Residual Representation for Group Activity Prediction, 
		Xiaolin Zhai, Zhengxi Hu, Dingye Yang, Shichao Wu, Jingtai Liu*, 
		<strong><a href="https://doi.org/10.1109/ICME55011.2023.00059">2023 IEEE International Conference on Multimedia & Expo (ICME)</a></strong>, 2023.
		[EI, CCF-B]</li>
		
		<br>
		<li> DisGait: A Prior Work of Gait Recognition Concerning Disguised Appearance and Pose, 
		Shouwang Huang*, Ruiqi Fan, and Shichao Wu, 
		<strong><a href="https://doi.org/10.1007/978-981-99-4742-3_34">International Conference on Intelligent Computing (ICIC)</a></strong>, 2023.
		[EI, CCF-C] </li>
		
		<br>
		<li> 考虑人类视线区域约束的机器人社交导航,
		胡郑希, 张千一, 翟晓琳, 吴仕超, 刘景泰*, 
		<strong><a href="https://doi.org/10.13973/j.cnki.robot.220405">机器人</a></strong>, 2023.		
		[EI] </li>
		
		<br>
		<li> Gaze Target Estimation Inspired by Interactive Attention, 
		Zhengxi Hu, Kunxu Zhao, Bohan Zhou, Hang Guo, Shichao Wu, Yuxue Yang, Jingtai Liu*, 
		<strong><a href="https://doi.org/10.1109/TCSVT.2022.3190314">IEEE Transactions on Circuits and Systems for Video Technology</a></strong>, 2022.		
		[SCI] </li>
		
		<br>
		<li> GA-STT: Human Trajectory Prediction With Group Aware Spatial-Temporal Transformer, 
		Lei Zhou, Dingye Yang, Xiaolin Zhai, Shichao Wu, Zhengxi Hu and Jingtai Liu*, 
		<strong><a href="https://doi.org/10.1109/LRA.2022.3176064">IEEE Robotics and Automation Letters</a></strong>, 2022.
		[SCI] </li>
		
		<br>
		<li> We Know Where They are Looking at from the RGB-D Camera: Gaze Following in 3D,
		Zhengxi Hu, Dingye Yang, Shilei Cheng, Lei Zhou, Shichao Wu and Jingtai Liu*, 
		<strong><a href="https://doi.org/10.1109/TIM.2022.3160534">IEEE Transactions on Instrumentation and Measurement</a></strong>, 2022.
		[SCI] </li>
		
		<br>
		<li> 面向共融机器人的交互意图理解与机器人主动舒适交互, 孙月, 吴仕超, 刘景泰*, 
		<strong><a href="https://doi.org/10.16453/j.cnki.ISSN2096-5036.2022.03.011">人工智能</a></strong>, 2022.
		</li>
		
		<br>
		<li> EEG Driving Fatigue Detection With PDC-Based Brain Functional Network, 
		Fei Wang*, Shichao Wu, Jingyu Ping, Zongfeng Xu and Hao Chu, 
		<strong><a href="https://doi.org/10.1109/JSEN.2021.3058658">IEEE Sensors Journal</a></strong>, 2021.
		[SCI] </li>
		
		<br>
		<li> Emotion Recognition with Convolutional Neural Network and EEG-Based EFDMs, 
		Fei Wang*, Shichao Wu, Weiwei Zhang, Zongfeng Xu, Yahui Zhang, Chengdong Wu, Sonya Coleman, 
		<strong><a href="https://doi.org/10.1016/j.neuropsychologia.2020.107506">Neuropsychologia</a></strong>, 2020.
		[SCI] </li>
		
		<br>
		<li> Multiple Nonlinear Features Fusion Based Driving Fatigue Detection, 
		Fei Wang*, Shichao Wu, Weiwei Zhang, Zhongfeng Xu, Yahui Zhang, Hao Chu, 
		<strong><a href="https://doi.org/10.1016/j.bspc.2020.102075">Biomedical Signal Processing and Control</a></strong>, 2020.		
		[SCI] </li>
		
		<br>
		<li> Partial Directed Coherence Based Graph Convolutional Neural Networks for Driving Fatigue Detection, 
		Weiwei Zhang, Fei Wang*, Shichao Wu, Zongfeng Xu, Jingyu Ping and Yang Jiang, 
		<strong><a href="https://doi.org/10.1063/5.0008434">Review of Scientific Instruments</a></strong>, 2020.
		[SCI] </li>
		
		<br>
		<li> Motor Imagery Classification Using Geodesic Filtering Common Spatial Pattern and Filter-bank Feature Weighted Support Vector Machine,
		Fei Wang*, Zongfeng Xu, Weiwei Zhang, Shichao Wu, Yahui Zhang, Jingyu Ping, and Chengdong Wu, 
		<strong><a href="https://doi.org/10.1063/1.5142343">Review of Scientific Instruments</a></strong>, 2020. 
		[SCI] </li>
		
		<br>
		<li> An Adaptive Control Approach for Intelligent Wheelchair Based on BCI Combining with QoO, 
		Fei Wang*, Zongfeng Xu, Weiwei Zhang, Shichao Wu, 
		<strong><a href="https://doi.org/10.1109/IJCNN48605.2020.9207175">International Joint Conference on Neural Networks</a></strong>, 2020.
		[EI, CCF-C] </li>
		
		<br>
		<li> 面向疲劳监测的EEG关键通道与频带分析研究, 吴仕超, 
		<strong><a href="https://doi.org/10.27007/d.cnki.gdbeu.2020.000041">东北大学硕士论文</a></strong>, 2020.
		</li>
		
		<br>
		<li> 基于脑电信号深度学习的驾驶疲劳监测, 
		王斐*, 吴仕超, 刘少林, 张亚徽, 
		<strong><a href="https://kns.cnki.net/kcms2/article/abstract?v=WONwD37cfzToUUrOaaqpBxDdL5OIQKs3povNT4K44LOs5QsiUrraMgVVmCvWl0x5ggFptedPahos9NknAiJXk0k1CxtncIVIqx-p_eLOXnBnzquexzNn84O96COGsJJ0&uniplatform=NZKPT&language=gb">电子与信息学报</a></strong>, 2019.
		[EI] </li>
		
		<br>
		<li> 基于稳态视觉诱发电位的智能轮椅半自主导航控制, 
		张亚徽, 王斐*, 李景宏, 刘玉强, 吴仕超, 
		<strong><a href="http://doi.org/10.13973/j.cnki.robot.180771">机器人</a></strong>, 2019. 
		[EI] </li>
		
		<br>
		<li> Cross-Subject EEG-Based Emotion Recognition with Deep Domain Confusion, 
		Weiwei Zhang, Fei Wang*, Yang Jiang, Zongfeng Xu, Shichao Wu, and Yahui Zhang, Sonya Coleman, 
		<strong><a href="https://doi.org/10.1007/978-3-030-27526-6_49">International Conference on Intelligent Robotics & Applications</a></strong>, 2019.
		[EI] </li>
		
		<br>
		<li> 基于图像层级的机器素描研究, 吴仕超, 刘满禄, 朱波, 李新茂, 
		<strong><a href="https://doi.org/10.15888/j.cnki.csa.005972">计算机系统应用</a></strong>, 2017.
		</li>
		
			
		<!--  Publications -->
		<!--
			<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
				<tr>
				<td style="padding:20px;width:100%;vertical-align:middle">
				  <heading>Selected Publication</heading>
				  <p>
				    My publications can be found <a href="https://scholar.google.com/citations?hl=zh-CN&user=dIBB8vsAAAAJ">here</a>. Here are some recent publications.
					Representative papers are <span class="highlight">highlighted</span>.
				  </p>
				</td>
			  </tr>
			</tbody></table>
			
			<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
			<tr  bgcolor="#ffffd0">
				<td style="padding:20px;width:25%;vertical-align:middle">
				  <a href="images/afpild.png"><img src="images/afpild.png" alt="afpild" width="240" height="160" style="border-style: none"></a>
				</td>
				<td width="75%" valign="middle">
				  <a href="https://doi.org/10.1016/j.inffus.2023.102181", target="_blank" id="afpild">
					<papertitle>AFPILD: Acoustic Footstep Dataset Collected Using One Microphone Array and LiDAR Sensor for Person Identification and Localization</papertitle>
				  </a>
				  <br>
				  <strong>Shichao Wu</strong>, Shouwang Huang, Zicheng Liu, Qianyi Zhang, Jingtai Liu*.
				  <br>
				  <em>Information Fusion</em>, 2023
				  <br>
				  <a href="https://doi.org/10.1016/j.inffus.2023.102181", target="_blank">paper</a> | <a href="data/afpild.bib", target="_blank">bibtex</a> | <a href="https://github.com/NkuSRLab/AFPILD-CRNN", target="_blank"><font color="red">dataset & code</font></a> 
				  <p>We build the acoustic footstep-based person identification and localization dataset (AFPILD) by unifying the identify and locate tasks for the first time, concerning the clothing and shoe type covariates.</p>
				</td>
			  </tr>
			  
			  
			<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
			<tr>
				<td style="padding:20px;width:25%;vertical-align:middle">
				  <a href="images/haac.png"><img src="images/haac.png" alt="haac" width="240" height="160" style="border-style: none"></a>
				</td>
				<td width="75%" valign="middle">
				  <a href="https://doi.org/10.1016/j.apacoust.2023.109541", target="_blank" id="haac">
					<papertitle>HAAC: Hierarchical Audio Augmentation Chain for ACCDOA Described Sound Event Localization and Detection</papertitle>
				  </a>
				  <br>
				  <strong>Shichao Wu</strong>, Yongru Wang, Zhengxi Hu, Jingtai Liu*.
				  <br>
				  <em>Applied Acoustics</em>, 2023
				  <br>
				  <a href="https://doi.org/10.1016/j.apacoust.2023.109541", target="_blank">paper</a> | <a href="data/haac.bib", target="_blank">bibtex</a> | <a href="https://github.com/NkuSRLab/HAAC-SELD", target="_blank">code</a> 
				  <p>We propose one hierarchical audio augmentation chain (HAAC) that contains feature map augmentation, audio channel swapping, and sample mixup to augment the audio features for the SELD task.  </p>
				</td>
			  </tr>			
			
						
			<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
			<tr  bgcolor="#ffffd0">
				<td style="padding:20px;width:25%;vertical-align:middle">
				  <a href="images/afpid.png"><img src="images/afpid.png" alt="afpid" width="240" height="160" style="border-style: none"></a>
				</td>
				<td width="75%" valign="middle">
				  <a href="https://www.sciencedirect.com/science/article/pii/S0950705123000813", target="_blank" id="afpid">
					<papertitle>Advanced Acoustic Footstep-based Person Identification Dataset and Method Using Multimodal Feature Fusion</papertitle>
				  </a>
				  <br>
				  <strong>Shichao Wu</strong>, Xiaolin Zhai, Zhengxi Hu, Yue Sun, Jingtai Liu*.
				  <br>
				  <em>Knowledge-Based Systems (KBS)</em>, 2023
				  <br>
				  <a href="https://www.sciencedirect.com/science/article/pii/S0950705123000813", target="_blank">paper</a> | <a href="data/afpid.bib", target="_blank">bibtex</a> | <a href="https://github.com/NkuSRLab/AFPIDII-AFPINet", target="_blank"><font color="red">dataset & code</font></a> 
				  <p>We propose one improved acoustic footstep-based person identification dataset (AFPID-II) from 41 subjects, counting over 14 h of footstep audios.</p>
				</td>
			  </tr>
			

			<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
			<tr  bgcolor="#ffffd0">
				<td style="padding:20px;width:25%;vertical-align:middle">
				  <a href="images/context_er_intro.png"><img src="images/context_er_intro.png" alt="context_er" width="240" height="160" style="border-style: none"></a>
				</td>
				<td width="75%" valign="middle">
				  <a href="https://ieeexplore.ieee.org/document/9868807", target="_blank" id="context_er">
					<papertitle>Hierarchical Context-Based Emotion Recognition with Scene Graphs</papertitle>
				  </a>
				  <br>
				  <strong>Shichao Wu</strong>, Lei Zhou, Zhengxi Hu, Jingtai Liu*.
				  <br>
				  <em>IEEE Transactions on Neural Networks and Learning Systems (TNNLS)</em>, 2022
				  <br>
				  <a href="https://ieeexplore.ieee.org/document/9868807", target="_blank">paper</a> | <a href="data/context_er.bib", target="_blank">bibtex</a>
				  <p>We propose the hierarchical contexts (the entity context, the global context, and the scene context) based emotion recognition method with scene graphs. </p>
				</td>
			  </tr>
			  
			  
			</tbody></table>
			
			-->	
			
			<!-- Website Acess Statistics -->
			<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
				<tr>
				<td style="padding:20px;width:100%;vertical-align:middle">
				  <heading>Visitor statistics (monthly)</heading>
				</td>
			  </tr>
			</tbody></table>
		<!-- Acess location maps -->
			<table style="width:50%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
			<tr>
			  <td style="padding:25px;width:25%;vertical-align:middle">
				<p style="text-align:center;font-size:small;">
				  <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=Nf9JLSPnh5kV19cJJX3LJrqsxQ0KiJ7YmpagTwstFxE&cl=ffffff&w=a"></script>
				  <!-- <script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=a&t=tt&d=Nf9JLSPnh5kV19cJJX3LJrqsxQ0KiJ7YmpagTwstFxE&co=2d78ad&ct=ffffff&cmo=3acc3a&cmn=ff5353"></script>  Total Pageviews -->
				</p>
			  </td>
			</tr>
			</tbody></table>

        </td>
    </tr>
</tbody></table>


</body></html>