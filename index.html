<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Shichao Wu</title>
  
  <meta name="author" content="Shichao Wu">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <!--<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>"> -->
  <link rel="icon" type="image/png" href="user_images/robots-and-humans.png">
  
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
	  
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Shichao Wu Âê¥‰ªïË∂Ö (Under construction)</name>
              </p>
              <p>
			  I am a third-year Ph.D. candidate in Artificial Intelligence at Nankai University, advised by Prof. Jingtai Liu. 
			  </p>
              <p>			  
			  I received my B.E. in Automation from Southwest University of Science and Technology, Mianyang, China, in 2017. 
			  After that, I spent two and a half years working with Prof. Fei Wang on EEG-based fatigue detection and brain-computer interface, to obtain my M.S. degree in Robot Science and Engineering from Northeastern University, Shenyang, China, in 2020. 
			  </p>
              <p style="text-align:center">
                <a href="shichaowu199@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/context_er_intro.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?hl=zh-CN&user=dIBB8vsAAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://blog.csdn.net/cratial">CSDN</a> &nbsp/&nbsp
                <a href="https://github.com/Cratial">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="user_images/shichaowu_silhouette.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="user_images/shichaowu_silhouette.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
		
		<!-- News Part -->
		<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>News</heading>
              <p>
                <ul>
				<li style="list-style-position:inside;margin:0;padding:0;text-align:left;"><strong>August 2022:</strong> Published one research paper concerning <a href="https://ieeexplore.ieee.org/abstract/document/9868807", target="_blank">context-aware emotion recognition</a> in IEEE Transactions on Neural Networks and Learning systems.</li>
				<!--
                  <li style="list-style-position:inside;margin:0;padding:0;text-align:left;">08/2022: I was awarded a best poster award at <a href="http://2022.semanticwebschool.org", target="_blank">ISWS </a>summer school in Bertinaro, Italy</li>
                  <li style="list-style-position:inside;margin:0;padding:0;text-align:left;">04/2022: I was accepted to <a href="http://2022.semanticwebschool.org", target="_blank">ISWS </a>summer school in Bertinaro, Italy</li>
                  <li style="list-style-position:inside;margin:0;padding:0;text-align:left;">02/2022: Our work on <a href="https://arxiv.org/abs/2202.01011", target="_blank">improving transfer learning using multi-armed bandits</a> was accepted to <a href="https://www.iclr.cc/", target="_blank">ICLR-22</a></li>
                  <li style="list-style-position:inside;margin:0;padding:0;text-align:left;">01/2022: Started my research co-advised by <a href="https://scholar.google.com/citations?user=JNPbTdIAAAAJ&hl=en" target="_blank">Professor James A. Hendler </a> and <a href="https://scholar.google.com/citations?user=Z_rAu6sAAAAJ&hl=en" target="_blank">Professor Chris R. Sims</a></li>
                  <li style="list-style-position:inside;margin:0;padding:0;text-align:left;">05/2021: Started a summer project with <a href="https://research.ibm.com/", target="_blank">Trustworthy AI and RL groups at IBM Research</a></li>
                  <li style="list-style-position:inside;margin:0;padding:0;text-align:left;">01/2021: Started MS/PhD in Computer Science at <a href="https://cs.rpi.edu/", target="_blank">Rensselaer Polytechnic Institute</a></li>
                  <li style="list-style-position:inside;margin:0;padding:0;text-align:left;">11/2020: Our work on <a href="https://www.biorxiv.org/content/10.1101/2021.01.28.428639v2.abstract", target="_blank">automated spectral unmixing</a> appeared on bioRxiv</li>
                  <li style="list-style-position:inside;margin:0;padding:0;text-align:left;">12/2018: Our work on <a href="https://link.springer.com/article/10.1007/s10827-018-0703-y", target="_blank">stochastic modeling of nerve fibers</a> appeared on <a href="https://www.springer.com/journal/10827", target="_blank">J Computational Neuroscience</a></li>
				  -->
                </ul>
              </p>
            </td>
          </tr>
        </tbody>
        </table>
		
		<!-- Research Part -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                My research interests include context-aware emotion recognition, sound events localization and localization (SELD), sound-enabled service robots, and embodied artificial intelligence. Representative papers are <span class="highlight">highlighted</span>.
              </p>
            </td>
          </tr>
        </tbody></table>
		

		<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
		<tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="user_images/context_er_intro.png" alt="context_er" width="240" height="180" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://ieeexplore.ieee.org/document/9868807", target="_blank" id="context_er">
                <papertitle>Hierarchical Context-Based Emotion Recognition With Scene Graphs</papertitle>
              </a>
              <br>
              <strong>Shichao Wu</strong>, Lei Zhou, Zhengxi Hu, Jingtai Liu*.
              <br>
              <em>TNNLS</em>, 2022
              <br>
              <a href="https://ieeexplore.ieee.org/document/9868807", target="_blank">paper</a> | <a href="user_data/context_er.bib", target="_blank">bibtex</a>
              <p>We propose the hierarchical contexts (the entity context, the global context, and the scene context) based emotion recognition method with scene graphs. </p>
            </td>
          </tr>
		  
		  
		  </tbody></table>
		
		
		
		<!--
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="dreamfusion_stop()" onmouseover="dreamfusion_start()"  bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='dreamfusion_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/dreamfusion.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/dreamfusion.jpg' width="160">
              </div>
              <script type="text/javascript">
                function dreamfusion_start() {
                  document.getElementById('dreamfusion_image').style.opacity = "1";
                }

                function dreamfusion_stop() {
                  document.getElementById('dreamfusion_image').style.opacity = "0";
                }
                dreamfusion_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://dreamfusion3d.github.io/">
                <papertitle>DreamFusion: Text-to-3D using 2D Diffusion</papertitle>
              </a>
              <br>
              <a href="https://cs.stanford.edu/~poole/">Ben Poole</a>,
              <a href="https://www.ajayj.com/">Ajay Jain</a>,
              <strong>Jonathan T. Barron</strong>,
			  <a href="https://bmild.github.io/">Ben Mildenhall</a>
              <br>
              <em>arXiv</em>, 2022
              <br>
              <a href="https://dreamfusion3d.github.io/">project page</a>
              /
              <a href="https://arxiv.org/abs/2209.14988">arXiv</a>
              /
              <a href="https://dreamfusion3d.github.io/gallery.html">gallery</a>
              <p></p>
              <p>
              We optimize a NeRF from scratch using a pretrained text-to-image diffusion model to do text-to-3D generative modeling.
              </p>
            </td>
          </tr>
		  

		<tr onmouseout="refnerf_stop()" onmouseover="refnerf_start()"  bgcolor="#ffffd0">
		  <td style="padding:20px;width:25%;vertical-align:middle">
			<div class="one">
			  <div class="two" id='refnerf_image'><video  width=100% height=100% muted autoplay loop>
			  <source src="images/refnerf.mp4" type="video/mp4">
			  Your browser does not support the video tag.
			  </video></div>
			  <img src='images/refnerf.jpg' width="160">
			</div>
			<script type="text/javascript">
			  function refnerf_start() {
				document.getElementById('refnerf_image').style.opacity = "1";
			  }

			  function refnerf_stop() {
				document.getElementById('refnerf_image').style.opacity = "0";
			  }
			  refnerf_stop()
			</script>
		  </td>
				<td style="padding:20px;width:75%;vertical-align:middle">
			  <a href="https://dorverbin.github.io/refnerf/index.html">
				<papertitle>Ref-NeRF: Structured View-Dependent Appearance for Neural Radiance Fields</papertitle>
			  </a>
			  <br>
			  <a href="https://scholar.harvard.edu/dorverbin/home">Dor Verbin</a>,
			  <a href="https://phogzone.com/">Peter Hedman</a>,
			  <a href="https://bmild.github.io/">Ben Mildenhall</a>, <br>
			  <a href="Todd Zickler">Todd Zickler</a>,
			  <strong>Jonathan T. Barron</strong>,
			  <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>
			  <br>
			  <em>CVPR</em>, 2022 &nbsp <font color="red"><strong>(Oral Presentation, Best Student Paper Honorable Mention)</strong></font>
			  <br>
			  <a href="https://dorverbin.github.io/refnerf/index.html">project page</a>
		/
			  <a href="https://arxiv.org/abs/2112.03907">arXiv</a>
		/
			  <a href="https://youtu.be/qrdRH9irAlk">video</a>
			  <p></p>
			  <p>Explicitly modeling reflections in NeRF produces realistic shiny surfaces and accurate surface normals, and lets you edit materials.</p>
			</td>
		  </tr>
				
				
          <tr onmouseout="mip360_stop()" onmouseover="mip360_start()"  bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='mip360_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/mip360_sat.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/mip360_sat.jpg' width="160">
              </div>
              <script type="text/javascript">
                function mip360_start() {
                  document.getElementById('mip360_image').style.opacity = "1";
                }

                function mip360_stop() {
                  document.getElementById('mip360_image').style.opacity = "0";
                }
                mip360_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://jonbarron.info/mipnerf360">
                <papertitle>Mip-NeRF 360: Unbounded Anti-Aliased Neural Radiance Fields</papertitle>
              </a>
              <br>
              <strong>Jonathan T. Barron</strong>,
              <a href="https://bmild.github.io/">Ben Mildenhall</a>,
              <a href="https://scholar.harvard.edu/dorverbin/home">Dor Verbin</a>,
              <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>,
              <a href="https://phogzone.com/">Peter Hedman</a>
              <br>
							<em>CVPR</em>, 2022 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              <a href="http://jonbarron.info/mipnerf360">project page</a>
              /
              <a href="https://arxiv.org/abs/2111.12077">arXiv</a>
              /
              <a href="https://youtu.be/zBSH-k9GbV4">video</a>
              <p></p>
              <p>mip-NeRF can be extended to produce realistic results on unbounded scenes.</p>
            </td>
          </tr> 


        </tbody></table>
		
		-->

		<!--		
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Misc</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
					
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>
            <td width="75%" valign="center">
              <a href="https://cvpr2022.thecvf.com/area-chairs">Area Chair, CVPR 2022</a>
              <br>
              <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair & Longuet-Higgins Award Committee Member, CVPR 2021</a>
              <br>
              <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
              <br>
              <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
            </td>
          </tr>
		  
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/cs188.jpg" alt="cs188">
            </td>
            <td width="75%" valign="center">
              <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor, CS188 Spring 2011</a>
              <br>
              <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor, CS188 Fall 2010</a>
              <br>
              <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd Edition</a>
            </td>
          </tr>
					
		
          <tr>
            <td align="center" style="padding:20px;width:25%;vertical-align:middle">
							<heading>Basically <br> Blog Posts</heading>
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2112.11687">Squareplus: A Softplus-Like Algebraic Rectifier</a>
              <br>
              <a href="https://arxiv.org/abs/2010.09714">A Convenient Generalization of Schlick's Bias and Gain Functions</a>
              <br>
              <a href="https://arxiv.org/abs/1704.07483">Continuously Differentiable Exponential Linear Units</a>
            </td>
          </tr>
		  			
        </tbody></table>
		-->
		
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                <br>
                Special thanks to <a href="https://jonbarron.info/">Jon Barron</a> for the website's <a href="https://github.com/jonbarron/jonbarron_website">source code</a>.
              </p>
			  <p style="text-align:right;font-size:small;">
                <br>
                Last updated: Nov. 2022.
              </p>
			  
            </td>
          </tr>
        </tbody></table>
		
		<table style="width:50%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
          <td style="padding:25px;width:25%;vertical-align:middle">
            <p style="text-align:center;font-size:small;">
              <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=Nf9JLSPnh5kV19cJJX3LJrqsxQ0KiJ7YmpagTwstFxE&cl=ffffff&w=a"></script>
              <!-- <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=Nf9JLSPnh5kV19cJJX3LJrqsxQ0KiJ7YmpagTwstFxE"></script>  -->
            </p>
          </td>
        </tr>
        </tbody></table>
		
		
      </td>
    </tr>
  </table>
</body>

</html>
