<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Shichao Wu</title>
  
  <meta name="author" content="Shichao Wu">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
	  
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Shichao Wu Âê¥‰ªïË∂Ö</name>
              </p>
              <p>
			  I am a third-year Ph.D. candidate in Artificial Intelligence at Nankai University, advised by Prof. Jingtai Liu. 
			  </p>
              <p>			  
			  I received my B.E. in Automation from Southwest University of Science and Technology, Mianyang, China, in 2017. 
			  After that, I spent two and a half years working with Prof. Fei Wang on EEG-based fatigue detection and brain-computer interface, to obtain my M.S. degree in Robot Science and Engineering from Northeastern University, Shenyang, China, in 2020. 
			  </p>
              <p style="text-align:center">
                <a href="shichaowu199@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/JonBarron-CV.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?hl=zh-CN&user=dIBB8vsAAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://blog.csdn.net/cratial">CSDN</a> &nbsp/&nbsp
                <a href="https://github.com/Cratial">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/shichaowu_silhouette.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="shichaowu_silhouette.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
		
		<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>News</heading>
              <p>
                <ul>
				<li style="list-style-position:inside;margin:0;padding:0;text-align:left;">08/2022: I was awarded a best poster award at <a href="http://2022.semanticwebschool.org", target="_blank">ISWS </a>summer school in Bertinaro, Italy</li>
				<!--
                  <li style="list-style-position:inside;margin:0;padding:0;text-align:left;">08/2022: I was awarded a best poster award at <a href="http://2022.semanticwebschool.org", target="_blank">ISWS </a>summer school in Bertinaro, Italy</li>
                  <li style="list-style-position:inside;margin:0;padding:0;text-align:left;">04/2022: I was accepted to <a href="http://2022.semanticwebschool.org", target="_blank">ISWS </a>summer school in Bertinaro, Italy</li>
                  <li style="list-style-position:inside;margin:0;padding:0;text-align:left;">02/2022: Our work on <a href="https://arxiv.org/abs/2202.01011", target="_blank">improving transfer learning using multi-armed bandits</a> was accepted to <a href="https://www.iclr.cc/", target="_blank">ICLR-22</a></li>
                  <li style="list-style-position:inside;margin:0;padding:0;text-align:left;">01/2022: Started my research co-advised by <a href="https://scholar.google.com/citations?user=JNPbTdIAAAAJ&hl=en" target="_blank">Professor James A. Hendler </a> and <a href="https://scholar.google.com/citations?user=Z_rAu6sAAAAJ&hl=en" target="_blank">Professor Chris R. Sims</a></li>
                  <li style="list-style-position:inside;margin:0;padding:0;text-align:left;">05/2021: Started a summer project with <a href="https://research.ibm.com/", target="_blank">Trustworthy AI and RL groups at IBM Research</a></li>
                  <li style="list-style-position:inside;margin:0;padding:0;text-align:left;">01/2021: Started MS/PhD in Computer Science at <a href="https://cs.rpi.edu/", target="_blank">Rensselaer Polytechnic Institute</a></li>
                  <li style="list-style-position:inside;margin:0;padding:0;text-align:left;">11/2020: Our work on <a href="https://www.biorxiv.org/content/10.1101/2021.01.28.428639v2.abstract", target="_blank">automated spectral unmixing</a> appeared on bioRxiv</li>
                  <li style="list-style-position:inside;margin:0;padding:0;text-align:left;">12/2018: Our work on <a href="https://link.springer.com/article/10.1007/s10827-018-0703-y", target="_blank">stochastic modeling of nerve fibers</a> appeared on <a href="https://www.springer.com/journal/10827", target="_blank">J Computational Neuroscience</a></li>
				  -->
                </ul>
              </p>
            </td>
          </tr>
        </tbody>
        </table>
		
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                My research interests include context-aware emotion recognition, sound events localization and localization (SELD), sound-enabled service robots, and embodied artificial intelligence. Representative papers are <span class="highlight">highlighted</span>.
              </p>
            </td>
          </tr>
        </tbody></table>
		
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="dreamfusion_stop()" onmouseover="dreamfusion_start()"  bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='dreamfusion_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/dreamfusion.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/dreamfusion.jpg' width="160">
              </div>
              <script type="text/javascript">
                function dreamfusion_start() {
                  document.getElementById('dreamfusion_image').style.opacity = "1";
                }

                function dreamfusion_stop() {
                  document.getElementById('dreamfusion_image').style.opacity = "0";
                }
                dreamfusion_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://dreamfusion3d.github.io/">
                <papertitle>DreamFusion: Text-to-3D using 2D Diffusion</papertitle>
              </a>
              <br>
              <a href="https://cs.stanford.edu/~poole/">Ben Poole</a>,
              <a href="https://www.ajayj.com/">Ajay Jain</a>,
              <strong>Jonathan T. Barron</strong>,
			  <a href="https://bmild.github.io/">Ben Mildenhall</a>
              <br>
              <em>arXiv</em>, 2022
              <br>
              <a href="https://dreamfusion3d.github.io/">project page</a>
              /
              <a href="https://arxiv.org/abs/2209.14988">arXiv</a>
              /
              <a href="https://dreamfusion3d.github.io/gallery.html">gallery</a>
              <p></p>
              <p>
              We optimize a NeRF from scratch using a pretrained text-to-image diffusion model to do text-to-3D generative modeling.
              </p>
            </td>
          </tr>
		  
          <tr onmouseout="samurai_stop()" onmouseover="samurai_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='samurai_image'>
                  <img src='images/samurai_after.jpg' width="160"></div>
                <img src='images/samurai_before.jpg' width="160">
              </div>
              <script type="text/javascript">
                function samurai_start() {
                  document.getElementById('samurai_image').style.opacity = "1";
                }

                function samurai_stop() {
                  document.getElementById('samurai_image').style.opacity = "0";
                }
                samurai_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://markboss.me/publication/2022-samurai/">
                <papertitle>SAMURAI: Shape And Material from Unconstrained Real-world Arbitrary Image Collections</papertitle>
              </a>
              <br>
              <a href="https://markboss.me">Mark Boss</a>, 
              <a href="">Andreas Engelhardt</a>, 
              <a href="https://abhishekkar.info/">Abhishek Kar</a>, 
              <a href="http://people.csail.mit.edu/yzli/">Yuanzhen Li</a>, 
              <a href="https://deqings.github.io/">Deqing Sun</a>, 
              <strong>Jonathan T. Barron</strong>,
              <a href="https://uni-tuebingen.de/en/faculties/faculty-of-science/departments/computer-science/lehrstuehle/computergrafik/computer-graphics/staff/prof-dr-ing-hendrik-lensch/">Hendrik P. A. Lensch</a>,
              <a href="https://varunjampani.github.io">Varun Jampani</a>
              <br>
              <em>NeurIPS</em>, 2022
              <br>
              <a href="https://markboss.me/publication/2022-samurai/">project page</a> /
              <a href="https://www.youtube.com/watch?v=LlYuGDjXp-8">video</a> /
              <a href="https://arxiv.org/abs/2205.15768">arXiv</a>
              <p></p>
              <p>
				A joint optimization framework for estimating shape, BRDF, camera pose, and illumination from in-the-wild image collections.
              </p>
            </td>
          </tr>		

          <tr onmouseout="pnf_stop()" onmouseover="pnf_start()">
          <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
          <div class="two" id='pnf_image'>
            <img src='images/pnf_before.jpg' width="160"></div>
          <img src='images/pnf_after.jpg' width="160">
          </div>
          <script type="text/javascript">
          function pnf_start() {
            document.getElementById('pnf_image').style.opacity = "1";
          }

          function pnf_stop() {
            document.getElementById('pnf_image').style.opacity = "0";
          }
          pnf_stop()
          </script>
          </td>
          <td style="padding:0;width:40%;max-width:40%">
          <a href="TODO">
          <papertitle>Polynomial Neural Fields for Subband Decomposition</papertitle>
          </a> <br>
          <a href="https://www.guandaoyang.com/">Guandao Yang*</a>,
          <a href="https://sagiebenaim.github.io/">Sagie Benaim*</a>,
          <a href="https://varunjampani.github.io/">Varun Jampani</a>,
          <a href="https://www.kylegenova.com/">Kyle Genova</a>,
          <strong>Jonathan T. Barron</strong>,
          <a href="https://www.cs.princeton.edu/~funk/">Thomas Funkhouser</a>,
          <a href="http://home.bharathh.info/">Bharath Hariharan</a>,
          <a href="https://sergebelongie.github.io/">Serge Belongie</a>
          <br>
          <em>NeurIPS</em>, 2022
          <p>
          Representing neural fields as a composition of manipulable and interpretable components lets you do things like reason about frequencies and scale.
          </p>
          </td>
          </tr> 


          <tr onmouseout="malle_stop()" onmouseover="malle_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='malle_image'>
                  <img src='images/MalleConv_after.jpg' width="160"></div>
                <img src='images/MalleConv_before.jpg' width="160">
              </div>
              <script type="text/javascript">
                function malle_start() {
                  document.getElementById('malle_image').style.opacity = "1";
                }

                function malle_stop() {
                  document.getElementById('malle_image').style.opacity = "0";
                }
                malle_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://yifanjiang.net/MalleConv.html">
                <papertitle>Fast and High-quality Image Denoising via Malleable Convolutions</papertitle>
              </a>
              <br>
              <a href="https://yifanjiang.net/">Yifan Jiang</a>,
              <a href="https://bartwronski.com/">Bartlomiej Wronski</a>, 
							<a href="https://bmild.github.io/">Ben Mildenhall</a>, <br>
              <strong>Jonathan T. Barron</strong>,
              <a href="https://spark.adobe.com/page/CAdrFMJ9QeI2y/">Zhangyang Wang</a>,
              <a href="https://people.csail.mit.edu/tfxue/">Tianfan Xue</a>
              <br>
              <em>ECCV</em>, 2022
              <br>
              <a href="https://yifanjiang.net/MalleConv.html">project page</a>
              /
              <a href="https://arxiv.org/abs/2201.00392">arXiv</a>
              <p></p>
              <p>
              We denoise images efficiently by predicting spatially-varying kernels at low resolution and using a fast fused op to jointly upsample and apply these kernels at full resolution.
              </p>
            </td>
          </tr>
					
          <tr onmouseout="nerfsuper_stop()" onmouseover="nerfsuper_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nerfsuper_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/nerf_supervision.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/nerf_supervision.jpg' width="160">
              </div>
              <script type="text/javascript">
                function nerfsuper_start() {
                  document.getElementById('nerfsuper_image').style.opacity = "1";
                }

                function nerfsuper_stop() {
                  document.getElementById('nerfsuper_image').style.opacity = "0";
                }
                nerfsuper_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="http://yenchenlin.me/nerf-supervision/">
                <papertitle>NeRF-Supervision: Learning Dense Object Descriptors from Neural Radiance Fields</papertitle>
              </a>
              <br>
              <a href="https://yenchenlin.me/">Lin Yen-Chen</a>, 
              <a href="http://www.peteflorence.com/">Pete Florence</a>, 
              <strong>Jonathan T. Barron</strong>,  <br>
              <a href="https://scholar.google.com/citations?user=_BPdgV0AAAAJ&hl=en">Tsung-Yi Lin</a>, 
              <a href="https://meche.mit.edu/people/faculty/ALBERTOR@MIT.EDU">Alberto Rodriguez</a>,
              <a href="http://web.mit.edu/phillipi/">Phillip Isola</a>
              <br>
              <em>ICRA</em>, 2022  
              <br>
							<a href="http://yenchenlin.me/nerf-supervision/">project page</a> / 
							<a href="https://arxiv.org/abs/2203.01913">arXiv</a> / 
							<a href="https://www.youtube.com/watch?v=_zN-wVwPH1s">video</a> /
							<a href="https://github.com/yenchenlin/nerf-supervision-public">code</a> / 
							<a href="https://colab.research.google.com/drive/13ISri5KD2XeEtsFs25hmZtKhxoDywB5y?usp=sharing">colab</a>				
              <p></p>
              <p>NeRF works better than RGB-D cameras or multi-view stereo when learning object descriptors.</p>
            </td>
          </tr>

			    <tr onmouseout="refnerf_stop()" onmouseover="refnerf_start()"  bgcolor="#ffffd0">
			      <td style="padding:20px;width:25%;vertical-align:middle">
			        <div class="one">
			          <div class="two" id='refnerf_image'><video  width=100% height=100% muted autoplay loop>
			          <source src="images/refnerf.mp4" type="video/mp4">
			          Your browser does not support the video tag.
			          </video></div>
			          <img src='images/refnerf.jpg' width="160">
			        </div>
			        <script type="text/javascript">
			          function refnerf_start() {
			            document.getElementById('refnerf_image').style.opacity = "1";
			          }

			          function refnerf_stop() {
			            document.getElementById('refnerf_image').style.opacity = "0";
			          }
			          refnerf_stop()
			        </script>
			      </td>
			            <td style="padding:20px;width:75%;vertical-align:middle">
			          <a href="https://dorverbin.github.io/refnerf/index.html">
			            <papertitle>Ref-NeRF: Structured View-Dependent Appearance for Neural Radiance Fields</papertitle>
			          </a>
			          <br>
			          <a href="https://scholar.harvard.edu/dorverbin/home">Dor Verbin</a>,
			          <a href="https://phogzone.com/">Peter Hedman</a>,
			          <a href="https://bmild.github.io/">Ben Mildenhall</a>, <br>
			          <a href="Todd Zickler">Todd Zickler</a>,
			          <strong>Jonathan T. Barron</strong>,
			          <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>
			          <br>
			    <em>CVPR</em>, 2022 &nbsp <font color="red"><strong>(Oral Presentation, Best Student Paper Honorable Mention)</strong></font>
			          <br>
			          <a href="https://dorverbin.github.io/refnerf/index.html">project page</a>
			    /
			          <a href="https://arxiv.org/abs/2112.03907">arXiv</a>
			    /
			          <a href="https://youtu.be/qrdRH9irAlk">video</a>
			          <p></p>
			          <p>Explicitly modeling reflections in NeRF produces realistic shiny surfaces and accurate surface normals, and lets you edit materials.</p>
			        </td>
			      </tr>
						
          <tr onmouseout="mip360_stop()" onmouseover="mip360_start()"  bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='mip360_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/mip360_sat.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/mip360_sat.jpg' width="160">
              </div>
              <script type="text/javascript">
                function mip360_start() {
                  document.getElementById('mip360_image').style.opacity = "1";
                }

                function mip360_stop() {
                  document.getElementById('mip360_image').style.opacity = "0";
                }
                mip360_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://jonbarron.info/mipnerf360">
                <papertitle>Mip-NeRF 360: Unbounded Anti-Aliased Neural Radiance Fields</papertitle>
              </a>
              <br>
              <strong>Jonathan T. Barron</strong>,
              <a href="https://bmild.github.io/">Ben Mildenhall</a>,
              <a href="https://scholar.harvard.edu/dorverbin/home">Dor Verbin</a>,
              <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>,
              <a href="https://phogzone.com/">Peter Hedman</a>
              <br>
							<em>CVPR</em>, 2022 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              <a href="http://jonbarron.info/mipnerf360">project page</a>
              /
              <a href="https://arxiv.org/abs/2111.12077">arXiv</a>
              /
              <a href="https://youtu.be/zBSH-k9GbV4">video</a>
              <p></p>
              <p>mip-NeRF can be extended to produce realistic results on unbounded scenes.</p>
            </td>
          </tr> 


        </tbody></table>

		<!--		
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Misc</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
					
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>
            <td width="75%" valign="center">
              <a href="https://cvpr2022.thecvf.com/area-chairs">Area Chair, CVPR 2022</a>
              <br>
              <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair & Longuet-Higgins Award Committee Member, CVPR 2021</a>
              <br>
              <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
              <br>
              <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
            </td>
          </tr>
		  
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/cs188.jpg" alt="cs188">
            </td>
            <td width="75%" valign="center">
              <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor, CS188 Spring 2011</a>
              <br>
              <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor, CS188 Fall 2010</a>
              <br>
              <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd Edition</a>
            </td>
          </tr>
					
		
          <tr>
            <td align="center" style="padding:20px;width:25%;vertical-align:middle">
							<heading>Basically <br> Blog Posts</heading>
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2112.11687">Squareplus: A Softplus-Like Algebraic Rectifier</a>
              <br>
              <a href="https://arxiv.org/abs/2010.09714">A Convenient Generalization of Schlick's Bias and Gain Functions</a>
              <br>
              <a href="https://arxiv.org/abs/1704.07483">Continuously Differentiable Exponential Linear Units</a>
            </td>
          </tr>
		  			
        </tbody></table>
		-->
		
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                <br>
                Special thanks to <a href="https://jonbarron.info/">Jon Barron for the website's <a href="https://github.com/jonbarron/jonbarron_website">source code</a>.
				Last updated on Nov. 2022.
              </p>
            </td>
          </tr>
        </tbody></table>
		
		<table style="width:25%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
          <td style="padding:25px;width:25%;vertical-align:middle">
            <p style="text-align:center;font-size:small;">
<!--              <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=400&t=tt&d=SmVNKAru4SRtedjTqTTFYIJmNGoHTrBK5VOIsscudyM'></script>-->
              <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=a&t=tt&d=SmVNKAru4SRtedjTqTTFYIJmNGoHTrBK5VOIsscudyM'></script>
              <!-- <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=GBSsEzAYyt4c8PKMCuVFdjM_Lwlz1U7drURBMMaLC60"></script>  -->
            </p>
          </td>
        </tr>
        </tbody></table>
		
		
      </td>
    </tr>
  </table>
</body>

</html>
